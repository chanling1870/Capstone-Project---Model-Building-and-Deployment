{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f785f-e229-4074-b966-86831ddf132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "\n",
    "def pick_input_csv():\n",
    "    cands = [\n",
    "        os.path.join(\"data\", \"bank.csv\"),\n",
    "        os.path.join(\"data\", \"raw\", \"dataset.csv\"),\n",
    "        os.path.join(\"data\", \"dataset.csv\"),\n",
    "    ]\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            return p\n",
    "    raise FileNotFoundError(\"File Not Found\")\n",
    "\n",
    "\n",
    "def setup_logger(log_dir=\"logs\"):\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    log_path = os.path.join(log_dir, \"pipeline.log\")\n",
    "\n",
    "    logger = logging.getLogger(\"capstone_min\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.handlers = []\n",
    "\n",
    "    fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n",
    "    fh = logging.FileHandler(log_path, encoding=\"utf-8\")\n",
    "    fh.setFormatter(fmt)\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(fmt)\n",
    "\n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(sh)\n",
    "    return logger, log_path\n",
    "\n",
    "\n",
    "def save_charts(y_test, pred, proba, df_all, out_dir, logger):\n",
    "    \"\"\"\n",
    "    Output 3 charts:\n",
    "    1) Target distribution histogram\n",
    "    2) Confusion matrix\n",
    "    3) Probability distribution (grouped by true label)\n",
    "    \"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # 1) target distribution\n",
    "    if \"deposit\" in df_all.columns:\n",
    "        plt.figure()\n",
    "        df_all[\"deposit\"].value_counts().plot(kind=\"bar\")\n",
    "        plt.title(\"Target Distribution (deposit)\")\n",
    "        plt.xlabel(\"deposit\")\n",
    "        plt.ylabel(\"count\")\n",
    "        p1 = os.path.join(out_dir, \"01_target_distribution.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(p1, dpi=160)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved chart: {p1}\")\n",
    "\n",
    "    # 2) Confusion matrix\n",
    "    cm = confusion_matrix(y_test, pred, labels=[0, 1])\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks([0, 1], [\"pred=0\", \"pred=1\"])\n",
    "    plt.yticks([0, 1], [\"true=0\", \"true=1\"])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    p2 = os.path.join(out_dir, \"02_confusion_matrix.png\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(p2, dpi=160)\n",
    "    plt.close()\n",
    "    logger.info(f\"Saved chart: {p2}\")\n",
    "\n",
    "    # 3) Probability distribution\n",
    "    if proba is not None:\n",
    "        y_arr = pd.Series(y_test).to_numpy()\n",
    "        p_arr = pd.Series(proba).to_numpy()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.hist(p_arr[y_arr == 0], bins=30, alpha=0.7, label=\"true=0\")\n",
    "        plt.hist(p_arr[y_arr == 1], bins=30, alpha=0.7, label=\"true=1\")\n",
    "        plt.title(\"Predicted Probability Distribution (by True Label)\")\n",
    "        plt.xlabel(\"P(deposit=yes)\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.legend()\n",
    "        p3 = os.path.join(out_dir, \"03_probability_distribution.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(p3, dpi=160)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved chart: {p3}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "    t0 = time.time()\n",
    "    logger, log_path = setup_logger()\n",
    "\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    os.makedirs(\"dashboards\", exist_ok=True)\n",
    "\n",
    "    in_path = pick_input_csv()\n",
    "    logger.info(f\"Input: {in_path}\")\n",
    "\n",
    "    df = pd.read_csv(in_path)\n",
    "    logger.info(f\"Raw shape: {df.shape}\")\n",
    "\n",
    "    # Cleaning: Standardize column names, remove duplicates, remove blank lines\n",
    "    df.columns = [str(c).strip().lower().replace(\" \", \"_\").replace(\"-\", \"_\") for c in df.columns]\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna(how=\"all\")\n",
    "\n",
    "    target = \"deposit\"\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column not found\")\n",
    "\n",
    "    # Target mapping yes/no -> 1/0 (using map + to_numeric here to completely avoid the downcasting warning of replace)\n",
    "    y_raw = df[target].astype(str).str.strip().str.lower()\n",
    "    y_mapped = y_raw.map({\"yes\": 1, \"no\": 0})\n",
    "    valid_mask = y_mapped.notna()\n",
    "    bad = int((~valid_mask).sum())\n",
    "    if bad > 0:\n",
    "        logger.info(f\"Drop rows with invalid target: {bad}\")\n",
    "\n",
    "    df = df.loc[valid_mask].copy()\n",
    "    y = y_mapped.loc[valid_mask].astype(int)\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # divide\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y if y.nunique() > 1 else None\n",
    "    )\n",
    "\n",
    "    # Process everything by category\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", Pipeline(steps=[\n",
    "                (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            ]), X.columns.tolist())\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocess\", pre),\n",
    "        (\"model\", LogisticRegression(max_iter=200))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = pipe.predict(X_test)\n",
    "    proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe, \"predict_proba\") else None\n",
    "\n",
    "    acc = float(accuracy_score(y_test, pred))\n",
    "    f1 = float(f1_score(y_test, pred, zero_division=0))\n",
    "    auc = float(roc_auc_score(y_test, proba)) if proba is not None and y_test.nunique() > 1 else None\n",
    "\n",
    "    metrics = {\n",
    "        \"input\": in_path,\n",
    "        \"rows\": int(df.shape[0]),\n",
    "        \"cols\": int(df.shape[1]),\n",
    "        \"train_rows\": int(len(X_train)),\n",
    "        \"test_rows\": int(len(X_test)),\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc,\n",
    "        \"run_time_sec\": round(time.time() - t0, 3),\n",
    "        \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    }\n",
    "    logger.info(f\"Metrics: acc={acc:.4f}, f1={f1:.4f}, auc={auc if auc is not None else 'NA'}\")\n",
    "\n",
    "    # Export metrics\n",
    "    metrics_path = os.path.join(\"outputs\", \"metrics.json\")\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # Export prediction\n",
    "    out_pred = X_test.copy()\n",
    "    out_pred[\"y_true\"] = list(y_test.values)\n",
    "    out_pred[\"y_pred\"] = list(pred)\n",
    "    if proba is not None:\n",
    "        out_pred[\"proba_yes\"] = list(proba)\n",
    "    pred_path = os.path.join(\"outputs\", \"predictions.csv\")\n",
    "    out_pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # Save model\n",
    "    model_path = os.path.join(\"models\", \"model.joblib\")\n",
    "    joblib.dump(pipe, model_path)\n",
    "\n",
    "    # Visualization\n",
    "    save_charts(\n",
    "        y_test=y_test,\n",
    "        pred=pred,\n",
    "        proba=proba,\n",
    "        df_all=df,\n",
    "        out_dir=\"dashboards\",\n",
    "        logger=logger\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Saved: {metrics_path}\")\n",
    "    logger.info(f\"Saved: {pred_path}\")\n",
    "    logger.info(f\"Saved: {model_path}\")\n",
    "    logger.info(\"Charts saved in: dashboards/\")\n",
    "    logger.info(f\"Log: {log_path}\")\n",
    "    logger.info(\"DONE\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
